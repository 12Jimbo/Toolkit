{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-09T13:04:59.469090Z",
     "iopub.status.busy": "2024-04-09T13:04:59.468570Z",
     "iopub.status.idle": "2024-04-09T13:05:00.608630Z",
     "shell.execute_reply": "2024-04-09T13:05:00.607354Z",
     "shell.execute_reply.started": "2024-04-09T13:04:59.469048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from testing_data import *\n",
    "import data_types as types\n",
    "import df_mappings as map\n",
    "import text_exploration as texplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_types', 'nan2nan', 'pd']\n"
     ]
    }
   ],
   "source": [
    "# Print out the names of all the functions in the data_types module\n",
    "print([item for item in dir(types) if not item.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Explore types with `col_types()`\n",
    "`types.col_types(df)` prints out the number of element types found in each column of a given pandas Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function col_types in module data_types:\n",
      "\n",
      "col_types(df)\n",
      "    '\n",
      "    In: a data frame df\n",
      "    Out: prints the number of element types found in each column of a given df\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(types.col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1 Column2 Column3\n",
      "0      1.0       A    True\n",
      "1      2.5       B   False\n",
      "2      3.0       C     NaN\n",
      "3      4.8       D       1\n",
      "4      5.0       5   Mixed \n",
      "\n",
      "Column1\n",
      "<class 'float'>    5\n",
      "Name: count, dtype: int64 \n",
      " NaN values:  0 \n",
      "\n",
      "Column2\n",
      "<class 'str'>    4\n",
      "<class 'int'>    1\n",
      "Name: count, dtype: int64 \n",
      " NaN values:  0 \n",
      "\n",
      "Column3\n",
      "<class 'bool'>     2\n",
      "<class 'float'>    1\n",
      "<class 'int'>      1\n",
      "<class 'str'>      1\n",
      "Name: count, dtype: int64 \n",
      " NaN values:  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_multitype,'\\n')\n",
    "\n",
    "types.col_types(df_multitype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Explore Same-Row NaNs with `nan2nan`\n",
    "`types.nan2nan` serves to answer the question: Are NaN values in col_1 also NaN in col 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function nan2nan in module data_types:\n",
      "\n",
      "nan2nan(df, col_1_name, col_2_name)\n",
      "    Given 2 columns in a data frame df, this function\n",
      "    returns a list with the number of NaNs in the first,\n",
      "    The number of NaNs in the second,\n",
      "    And the number fo rows where both cols have NaN value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(types.nan2nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1 Column2 Column3\n",
      "0      1.0       A    True\n",
      "1      NaN       B     NaN\n",
      "2      NaN     NaN     NaN\n",
      "3      4.0     NaN    True\n",
      "4      5.0       E   False \n",
      "\n",
      "NaN values in Column1:  2 \n",
      "\n",
      "NaN values in Column2:  2 \n",
      "\n",
      "NaN values in the same row for both Column1 and Column2:  1\n"
     ]
    }
   ],
   "source": [
    "print(df_nans,'\\n')\n",
    "\n",
    "types.nan2nan(df_nans, 'Column1', 'Column2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T13:05:00.620617Z",
     "iopub.status.busy": "2024-04-09T13:05:00.620057Z",
     "iopub.status.idle": "2024-04-09T13:05:00.632785Z",
     "shell.execute_reply": "2024-04-09T13:05:00.631989Z",
     "shell.execute_reply.started": "2024-04-09T13:05:00.620589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foreign_k2k', 'map_col2col', 'occurrences', 'pd', 'xs2xs', 'xs2ys']\n"
     ]
    }
   ],
   "source": [
    "# Print out the names of all the functions in the df_mappings module\n",
    "print([item for item in dir(map) if not item.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Which values are in the same position?\n",
    "`maps.map_col2col`: given 2 columns in a data frame (or any two same length columns), one might be interested in how they map onto each other. Is it a 1 to 1 mapping? Does it define a function? And if so, is the function injective of surjective?\n",
    "\n",
    "The following function, given col_1 and col_2, returns, for each value in col_1, how many values it is associated to in col_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function map_col2col in module df_mappings:\n",
      "\n",
      "map_col2col(series_1, series_2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(map.map_col2col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T13:05:00.658096Z",
     "iopub.status.busy": "2024-04-09T13:05:00.657182Z",
     "iopub.status.idle": "2024-04-09T13:05:00.669167Z",
     "shell.execute_reply": "2024-04-09T13:05:00.668314Z",
     "shell.execute_reply.started": "2024-04-09T13:05:00.658068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b      c\n",
      "0  1  1  lollo\n",
      "1  2  3  gigio\n",
      "2  3  1  lollo\n",
      "3  4  3  gigio\n",
      "4  3  1  lollo \n",
      "\n",
      "   gigio  lollo\n",
      "1  False   True\n",
      "3   True  False\n"
     ]
    }
   ],
   "source": [
    "# Try it out here:\n",
    "print(df_maps1, '\\n')\n",
    "print(map_col2col(df_maps1.b, df_maps1.c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling `map_count(col_1, col_2)` and then `map_count(col_2, col_1)`, one will be able to determine the relation between the two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Can 2 same type series get a 1 to 1 mapping?\n",
    "`map.foreign_k2k`: are you wandering whether two columns from different tables have the same unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function foreign_k2k in module df_mappings:\n",
      "\n",
      "foreign_k2k(series_1, series_2, df1_name='table1', df2_name='table2', n_matches=-1, mode='>')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(map.foreign_k2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T13:05:00.691962Z",
     "iopub.status.busy": "2024-04-09T13:05:00.691260Z",
     "iopub.status.idle": "2024-04-09T13:05:00.703870Z",
     "shell.execute_reply": "2024-04-09T13:05:00.703093Z",
     "shell.execute_reply.started": "2024-04-09T13:05:00.691936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table1.a_values</th>\n",
       "      <th>matches_in_table2.b &gt; -1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   table1.a_values  matches_in_table2.b > -1\n",
       "0                1                         2\n",
       "1                2                         0\n",
       "2                3                         1\n",
       "3                4                         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "map.foreign_k2k(df_maps2.a, df_maps2.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 xs2xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_1 = [1, 2, 3, 4, 5, 6, np.nan, np.nan, 3, 3]\n",
    "iter_2 = [1, 5, 3, 3, 4, 5, 8, np.nan]\n",
    "\n",
    "i1 = pd.Series(iter_1)\n",
    "i2 = pd.Series(iter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(i1[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame()\n",
    "# Assigning names to the columns\n",
    "values = 'All values'\n",
    "name_1 = 'iter_1'\n",
    "name_2 = 'iter_2'\n",
    "count_1 = f'occurrences in {name_1}'\n",
    "count_2 = f'occurrences in {name_2}'\n",
    "# Create a DataFrame with unique values from both iterators\n",
    "r[values] = pd.concat([i1, i2]).unique()\n",
    "\n",
    "# Count occurrences of each unique value in the first iterator, managing NaN values\n",
    "r[count_1] = r[values].map(lambda x: i1.value_counts()[x] if x in i1.value_counts() else i1.isna().sum() if pd.isna(x) else 0)\n",
    "\n",
    "# Count occurrences of each unique value in the second iterator, managing NaN values\n",
    "r[count_2] = r[values].map(lambda x: i2.value_counts()[x] if x in i2.value_counts() else i2.isna().sum() if pd.isna(x) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = r[values][0]\n",
    "i1.value_counts()[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   All values  occurrences in iter_1  occurrences in iter_2\n",
      "0         1.0                      1                      1\n",
      "1         2.0                      1                      0\n",
      "2         3.0                      3                      2\n",
      "3         4.0                      1                      1\n",
      "4         5.0                      1                      2\n",
      "5         6.0                      1                      0\n",
      "6         NaN                      2                      1\n",
      "7         8.0                      0                      1\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xs2xs(iter_1, iter_2, name_1 = 'iter_1', name_2 = 'iter_2'):\n",
    "    '''\n",
    "    This function is intended to check whether two iterables have the same values, i.e. whether a 1 to 1 mapping is possible.\n",
    "    Provided iter_1 and iter_2, xs2xs checks whether there are values in one of them that are absent in the other.\n",
    "    It returns a data frame where the first field lists all values in either iterable; the second field indicates how many occurrences\n",
    "    of the element are present in iter_1; the third field ndicates how many occurrences of the element are present in iter_2. The\n",
    "    data frame is ordered as to show first the elements present in only one of the two iterables.\n",
    "    '''\n",
    "    r = pd.DataFrame()\n",
    "    i1 = pd.Series(iter_1)\n",
    "    i2 = pd.Series(iter_2)\n",
    "\n",
    "    # Assigning names to the columns\n",
    "    values = 'All values'\n",
    "    count_1 = f'occurrences in {name_1}'\n",
    "    count_2 = f'occurrences in {name_2}'\n",
    "    # Create a DataFrame with unique values from both iterators\n",
    "    r[values] = pd.concat([i1, i2]).unique()\n",
    "    \n",
    "    # Count occurrences of each unique value in the first iterator (if-else bc NaNs would be counted NaNs by value_counts)\n",
    "    r[count_1] = r[values].map(lambda x: i1.isna().sum() if pd.isna(x) else i1.value_counts())\n",
    "    \n",
    "    # Count occurrences of each unique value in the second iterator\n",
    "    r[count_2] = r[values].map(i2.value_counts())\n",
    "\n",
    "    # NaN values counts actually indicate 0 occurrences \n",
    "    # r[count_1] = r[count_1].fillna(0)\n",
    "    # r[count_2] = r[count_2].fillna(0)\n",
    "\n",
    "    # Show unmatched values first\n",
    "    r = r.sort_values(by=[count_1, count_2], ascending=[True, True])\n",
    "\n",
    "    # Print stuff that is good to know:\n",
    "    # 1. The number of NaNs in each iterator\n",
    "    nans_1 = i1.isna().sum()\n",
    "    nans_1_relative = nans_1 / len(i1) * 100\n",
    "    nans_2 = i2.isna().sum()\n",
    "    nans_2_relative = nans_2 / len(i2) * 100\n",
    "    # 2. The percentage of 1 to 1 mapping\n",
    "    unmatched = ((r[count_1] == 0) | (r[count_2] == 0)).sum()\n",
    "    unmatched_relative = unmatched / len(r) * 100\n",
    "    bijective_mapping_relative = 100 - unmatched_relative\n",
    "\n",
    "    print(f'Number of NaNs in {name_1}: {nans_1} ({nans_1_relative:.2f}%)')\n",
    "    print(f'Number of NaNs in {name_2}: {nans_2} ({nans_2_relative:.2f}%)')\n",
    "    print(f'Percentage of unmatched values: {unmatched_relative:.2f}%')\n",
    "    print(f'Percentage of bijective mapping: {bijective_mapping_relative:.2f}%')\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:460\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     codes, categories = \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/algorithms.py:795\u001b[39m, in \u001b[36mfactorize\u001b[39m\u001b[34m(values, sort, use_na_sentinel, size_hint)\u001b[39m\n\u001b[32m    793\u001b[39m             values = np.where(null_mask, na_value, values)\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     codes, uniques = \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/algorithms.py:595\u001b[39m, in \u001b[36mfactorize_array\u001b[39m\u001b[34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[39m\n\u001b[32m    594\u001b[39m table = hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m uniques, codes = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7281\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'Series'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mxs2xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_2\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mxs2xs\u001b[39m\u001b[34m(iter_1, iter_2, name_1, name_2)\u001b[39m\n\u001b[32m     24\u001b[39m r[count_2] = r[values].map(i2.value_counts())\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# NaN values counts actually indicate 0 occurrences \u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# r[count_1] = r[count_1].fillna(0)\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# r[count_2] = r[count_2].fillna(0)\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Show unmatched values first\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m r = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount_2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Print stuff that is good to know:\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 1. The number of NaNs in each iterator\u001b[39;00m\n\u001b[32m     35\u001b[39m nans_1 = i1.isna().sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:7183\u001b[39m, in \u001b[36mDataFrame.sort_values\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   7176\u001b[39m         \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[32m   7177\u001b[39m         \u001b[38;5;66;03m# expected List[ndarray]\u001b[39;00m\n\u001b[32m   7178\u001b[39m         keys = [\n\u001b[32m   7179\u001b[39m             Series(k, name=name)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   7180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m (k, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, by)\n\u001b[32m   7181\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m7183\u001b[39m     indexer = \u001b[43mlexsort_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\n\u001b[32m   7185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7186\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[32m   7187\u001b[39m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7189\u001b[39m     k = \u001b[38;5;28mself\u001b[39m._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/sorting.py:351\u001b[39m, in \u001b[36mlexsort_indexer\u001b[39m\u001b[34m(keys, orders, na_position, key, codes_given)\u001b[39m\n\u001b[32m    349\u001b[39m     n = codes.max() + \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(codes) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     cat = \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m     codes = cat.codes\n\u001b[32m    353\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(cat.categories)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:462\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[39m\n\u001b[32m    460\u001b[39m     codes, categories = factorize(values, sort=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     codes, categories = \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype.ordered:\n\u001b[32m    464\u001b[39m         \u001b[38;5;66;03m# raise, as we don't have a sortable data structure and so\u001b[39;00m\n\u001b[32m    465\u001b[39m         \u001b[38;5;66;03m# the user should give us one by specifying categories\u001b[39;00m\n\u001b[32m    466\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    467\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not ordered, please \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    468\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mexplicitly specify the categories order \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    469\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mby passing in a categories argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/algorithms.py:795\u001b[39m, in \u001b[36mfactorize\u001b[39m\u001b[34m(values, sort, use_na_sentinel, size_hint)\u001b[39m\n\u001b[32m    792\u001b[39m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[32m    793\u001b[39m             values = np.where(null_mask, na_value, values)\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     codes, uniques = \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m0\u001b[39m:\n\u001b[32m    802\u001b[39m     uniques, codes = safe_sort(\n\u001b[32m    803\u001b[39m         uniques,\n\u001b[32m    804\u001b[39m         codes,\n\u001b[32m   (...)\u001b[39m\u001b[32m    807\u001b[39m         verify=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    808\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/algorithms.py:595\u001b[39m, in \u001b[36mfactorize_array\u001b[39m\u001b[34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[39m\n\u001b[32m    592\u001b[39m hash_klass, values = _get_hashtable_algo(values)\n\u001b[32m    594\u001b[39m table = hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m uniques, codes = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[32m    604\u001b[39m uniques = _reconstruct_data(uniques, original.dtype, original)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7281\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "print(xs2xs(iter_1, iter_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore your text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finals', 'initials', 'pd']\n"
     ]
    }
   ],
   "source": [
    "# Print out the names of all the functions in the text_exploration module\n",
    "print([item for item in dir(texplo) if not item.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Need trimming?\n",
    "A long column of strings sometimes starts with undesirable characters like brackets or others. Let's quickly check what are the initials of our strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function initials in module text_exploration:\n",
      "\n",
      "initials(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(texplo.initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function finals in module text_exploration:\n",
      "\n",
      "finals(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(texplo.finals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Column1 Column2    Column3\n",
      "0       ##apple##     A1     @hello@\n",
      "1        banana!!     B2   !!world!!\n",
      "2      %%cherry%%     C3     python \n",
      "3          date@@     D4     rocks@@\n",
      "4  @@elderberry@@     E5        None \n",
      "\n",
      "Column3\n",
      "@       2\n",
      "!       1\n",
      "        1\n",
      "None    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_text, '\\n')\n",
    "\n",
    "print(texplo.finals(df_text.Column3))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
