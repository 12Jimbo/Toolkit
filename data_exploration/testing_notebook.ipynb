{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-09T13:04:59.469090Z",
     "iopub.status.busy": "2024-04-09T13:04:59.468570Z",
     "iopub.status.idle": "2024-04-09T13:05:00.608630Z",
     "shell.execute_reply": "2024-04-09T13:05:00.607354Z",
     "shell.execute_reply.started": "2024-04-09T13:04:59.469048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import text_exploration as texplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few dataframes for testing:\n",
    "\n",
    "data_multitype = {\n",
    "    'Column1': [1, 2.5, 3, 4.8, 5],     # Mixed integers and floats\n",
    "    'Column2': ['A', 'B', 'C', 'D', 5], # Strings and an integer\n",
    "    'Column3': [True, False, np.nan, 1, 'Mixed']  # Booleans, NaN, integer, and string\n",
    "}\n",
    "\n",
    "df_multitype = pd.DataFrame(data_multitype)\n",
    "\n",
    "data_nans = {\n",
    "    'Column1': [1, np.nan, np.nan, 4, 5],       # Contains NaN values\n",
    "    'Column2': ['A', 'B', np.nan, np.nan, 'E'], # Contains NaN values\n",
    "    'Column3': [True, np.nan, np.nan, True, False]  # Contains NaN values\n",
    "}\n",
    "\n",
    "df_nans = pd.DataFrame(data_nans)\n",
    "\n",
    "df_maps1 = pd.DataFrame(\n",
    "    {\n",
    "        'a': [1, 2, 3, 4, 3],\n",
    "        'b': [1, 3, 1, 3, 1],\n",
    "        'c': ['lollo', 'gigio', 'lollo', 'gigio', 'lollo']\n",
    "    })\n",
    "\n",
    "df_maps2 = pd.DataFrame(\n",
    "    {\n",
    "        'a': [1, 2, 3, 4],\n",
    "        'b': [1, 1, 3, 5]\n",
    "    }\n",
    ")\n",
    "\n",
    "data_text = {\n",
    "    'Column1': ['##apple##', 'banana!!', '%%cherry%%', 'date@@', '@@elderberry@@'],  # Repeated special characters\n",
    "    'Column2': [' A1 ', ' B2 ', ' C3 ', ' D4 ', ' E5 '],                             # Leading/trailing spaces\n",
    "    'Column3': ['@hello@', '!!world!!', ' python ', 'rocks@@', None]                # Mixed issues\n",
    "}\n",
    "\n",
    "df_text = pd.DataFrame(data_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_types', 'nan2nan', 'pd']\n"
     ]
    }
   ],
   "source": [
    "import data_types as types\n",
    "\n",
    "# Print out the names of all the functions in the data_types module\n",
    "print([item for item in dir(types) if not item.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Explore types with `col_types()`\n",
    "`types.col_types(df)` prints out the number of element types found in each column of a given pandas Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function col_types in module data_types:\n",
      "\n",
      "col_types(df)\n",
      "    '\n",
      "    In: a data frame df\n",
      "    Out: prints the number of element types found in each column of a given df\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(types.col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1 Column2 Column3\n",
      "0      1.0       A    True\n",
      "1      2.5       B   False\n",
      "2      3.0       C     NaN\n",
      "3      4.8       D       1\n",
      "4      5.0       5   Mixed \n",
      "\n",
      "Column1\n",
      "<class 'float'>    5\n",
      "Name: count, dtype: int64 \n",
      " NaN values:  0 \n",
      "\n",
      "Column2\n",
      "<class 'str'>    4\n",
      "<class 'int'>    1\n",
      "Name: count, dtype: int64 \n",
      " NaN values:  0 \n",
      "\n",
      "Column3\n",
      "<class 'bool'>     2\n",
      "<class 'float'>    1\n",
      "<class 'int'>      1\n",
      "<class 'str'>      1\n",
      "Name: count, dtype: int64 \n",
      " NaN values:  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_multitype,'\\n')\n",
    "\n",
    "types.col_types(df_multitype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Explore Matching NaNs with `nan2nan`\n",
    "`types.nan2nan` serves to answer the question: Are NaN values in col_1 also NaN in col 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function nan2nan in module data_types:\n",
      "\n",
      "nan2nan(df, col_1_name, col_2_name)\n",
      "    Given 2 columns in a data frame df, this function\n",
      "    returns a list with the number of NaNs in the first,\n",
      "    The number of NaNs in the second,\n",
      "    And the number fo rows where both cols have NaN value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(types.nan2nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1 Column2 Column3\n",
      "0      1.0       A    True\n",
      "1      NaN       B     NaN\n",
      "2      NaN     NaN     NaN\n",
      "3      4.0     NaN    True\n",
      "4      5.0       E   False \n",
      "\n",
      "NaN values in Column1:  2 \n",
      "\n",
      "NaN values in Column2:  2 \n",
      "\n",
      "NaN values in the same row for both Column1 and Column2:  1\n"
     ]
    }
   ],
   "source": [
    "print(df_nans,'\\n')\n",
    "\n",
    "types.nan2nan(df_nans, 'Column1', 'Column2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T13:05:00.620617Z",
     "iopub.status.busy": "2024-04-09T13:05:00.620057Z",
     "iopub.status.idle": "2024-04-09T13:05:00.632785Z",
     "shell.execute_reply": "2024-04-09T13:05:00.631989Z",
     "shell.execute_reply.started": "2024-04-09T13:05:00.620589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foreign_k2k', 'map_col2col', 'occurrences', 'pd', 'xs2xs', 'xs2ys']\n"
     ]
    }
   ],
   "source": [
    "import df_mappings as map\n",
    "\n",
    "# Print out the names of all the functions in the df_mappings module\n",
    "print([item for item in dir(map) if not item.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Which values are in the same position?\n",
    "`maps.map_col2col`: given 2 columns in a data frame (or any two same length columns), one might be interested in how they map onto each other. Is it a 1 to 1 mapping? Does it define a function? And if so, is the function injective of surjective?\n",
    "\n",
    "The following function, given col_1 and col_2, returns, for each value in col_1, how many values it is associated to in col_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function map_col2col in module df_mappings:\n",
      "\n",
      "map_col2col(series_1, series_2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(map.map_col2col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T13:05:00.658096Z",
     "iopub.status.busy": "2024-04-09T13:05:00.657182Z",
     "iopub.status.idle": "2024-04-09T13:05:00.669167Z",
     "shell.execute_reply": "2024-04-09T13:05:00.668314Z",
     "shell.execute_reply.started": "2024-04-09T13:05:00.658068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b      c\n",
      "0  1  1  lollo\n",
      "1  2  3  gigio\n",
      "2  3  1  lollo\n",
      "3  4  3  gigio\n",
      "4  3  1  lollo \n",
      "\n",
      "   gigio  lollo\n",
      "1  False   True\n",
      "3   True  False\n"
     ]
    }
   ],
   "source": [
    "# Try it out here:\n",
    "print(df_maps1, '\\n')\n",
    "print(map_col2col(df_maps1.b, df_maps1.c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling `map_count(col_1, col_2)` and then `map_count(col_2, col_1)`, one will be able to determine the relation between the two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Can 2 same type series get a 1 to 1 mapping?\n",
    "`map.foreign_k2k`: are you wandering whether two columns from different tables have the same unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function foreign_k2k in module df_mappings:\n",
      "\n",
      "foreign_k2k(series_1, series_2, df1_name='table1', df2_name='table2', n_matches=-1, mode='>')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(map.foreign_k2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T13:05:00.691962Z",
     "iopub.status.busy": "2024-04-09T13:05:00.691260Z",
     "iopub.status.idle": "2024-04-09T13:05:00.703870Z",
     "shell.execute_reply": "2024-04-09T13:05:00.703093Z",
     "shell.execute_reply.started": "2024-04-09T13:05:00.691936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table1.a_values</th>\n",
       "      <th>matches_in_table2.b &gt; -1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   table1.a_values  matches_in_table2.b > -1\n",
       "0                1                         2\n",
       "1                2                         0\n",
       "2                3                         1\n",
       "3                4                         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "map.foreign_k2k(df_maps2.a, df_maps2.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 xs2xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_1 = [1, 2, 3, 4, 5, 6]\n",
    "iter_2 = [1, 5, 3, 3, 4, 5, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43miter_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:448\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    445\u001b[39m objs, keys = \u001b[38;5;28mself\u001b[39m._clean_keys_and_objs(objs, keys)\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m ndims = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_ndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m sample, objs = \u001b[38;5;28mself\u001b[39m._get_sample_object(objs, ndims, keys, names, levels)\n\u001b[32m    451\u001b[39m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:489\u001b[39m, in \u001b[36m_Concatenator._get_ndims\u001b[39m\u001b[34m(self, objs)\u001b[39m\n\u001b[32m    484\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[32m    485\u001b[39m         msg = (\n\u001b[32m    486\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot concatenate object of type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33monly Series and DataFrame objs are valid\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    488\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m    491\u001b[39m     ndims.add(obj.ndim)\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[31mTypeError\u001b[39m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "pd.concat([iter_1, iter_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mxs2xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_2\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Toolkit/data_exploration/df_mappings.py:90\u001b[39m, in \u001b[36mxs2xs\u001b[39m\u001b[34m(iter_1, iter_2, name_1, name_2)\u001b[39m\n\u001b[32m     87\u001b[39m i2 = pd.Series(iter_2)\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Create a DataFrame with unique values from both iterators\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m r[\u001b[33m'\u001b[39m\u001b[33miter_1 U iter_2\u001b[39m\u001b[33m'\u001b[39m] = pd.concat([i1, i2]).unique()\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Count occurrences of each unique value in the first iterator\u001b[39;00m\n\u001b[32m     92\u001b[39m r[\u001b[33m'\u001b[39m\u001b[33mcount in iter_1\u001b[39m\u001b[33m'\u001b[39m] = r[\u001b[33m'\u001b[39m\u001b[33miter_1 U iter_2\u001b[39m\u001b[33m'\u001b[39m].map(i1.value_counts())\n",
      "\u001b[31mNameError\u001b[39m: name 'concat' is not defined"
     ]
    }
   ],
   "source": [
    "print(map.xs2xs(iter_1, iter_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore your text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finals', 'initials', 'pd']\n"
     ]
    }
   ],
   "source": [
    "import text_exploration as texplo\n",
    "\n",
    "# Print out the names of all the functions in the text_exploration module\n",
    "print([item for item in dir(texplo) if not item.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Need trimming?\n",
    "A long column of strings sometimes starts with undesirable characters like brackets or others. Let's quickly check what are the initials of our strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function initials in module text_exploration:\n",
      "\n",
      "initials(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(texplo.initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function finals in module text_exploration:\n",
      "\n",
      "finals(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(texplo.finals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Column1 Column2    Column3\n",
      "0       ##apple##     A1     @hello@\n",
      "1        banana!!     B2   !!world!!\n",
      "2      %%cherry%%     C3     python \n",
      "3          date@@     D4     rocks@@\n",
      "4  @@elderberry@@     E5        None \n",
      "\n",
      "Column3\n",
      "@       2\n",
      "!       1\n",
      "        1\n",
      "None    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_text, '\\n')\n",
    "\n",
    "print(texplo.finals(df_text.Column3))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
